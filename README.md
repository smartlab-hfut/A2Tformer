# A2Tformer

**A2Tformer** is a Transformer-based deep learning model for non-stationary time series classification.  
It introduces a novel autocorrelation-based attention mechanism (AÂ²T) and a Learnable Wavelet Attention module to enhance robustness.

---

## ğŸ§  Core Features

- ğŸ“Œ AÂ²T: attention based on autocorrelation function, replacing positional encoding
- ğŸ” Dual-branch design: frequency-aware wavelet attention + time-domain attention
- ğŸ§ª Strong performance on UCR archive with fewer parameters

---

## ğŸ“ Project Structure

```bash
â”œâ”€â”€ main.py              # Main training script
â”œâ”€â”€ model.py             # Transformer model with AÂ²T and PWTM
â”œâ”€â”€ dataprosess.py       # Data loading and normalization
â”œâ”€â”€ test_model.py        # Evaluation and plotting
â”œâ”€â”€ config.json          # Dataset configurations (optional)
â”œâ”€â”€ requirements.txt     # Dependencies
â”œâ”€â”€ train_ucr.sh         # Train all datasets
```

---

## ğŸš€ Getting Started

```bash
git clone https://github.com/your-name/A2Tformer.git
cd A2Tformer
pip install -r requirements.txt
bash train_ucr.sh
```

---

## ğŸ“Š Datasets

The model supports all UCR 2018 datasets. Please place the dataset under:

```plaintext
./data/UCRArchive_2018/<DatasetName>/<DatasetName>_TRAIN.tsv
./data/UCRArchive_2018/<DatasetName>/<DatasetName>_TEST.tsv
```

---

## ğŸ“ˆ Visualization

You may enable feature visualization in `main.py` and generate:

- `viewdata/*.npy`: feature tensors before & after FFN
- `plots/*.png`: training curves
- `reports/*.csv`: classification reports

---

## ğŸ“„ License

MIT License.

---

## ğŸ“¬ Contact

Feel free to reach out for collaborations or questions.

- ğŸ“§ luohuan@mail.hfut.edu.cn
- ğŸ“§ liqiyue@mail.ustc.edu.cn
